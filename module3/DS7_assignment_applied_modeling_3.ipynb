{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Applied Modeling, Module 3\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [X] Continue to iterate on your project: data cleaning, exploration, feature engineering, modeling.\n",
    "- [ ] Make at least 1 partial dependence plot to explain your model.\n",
    "- [ ] Share at least 1 visualization on Slack.\n",
    "\n",
    "(If you have not yet completed an initial model yet for your portfolio project, then do today's assignment using your Tanzania Waterpumps model.)\n",
    "\n",
    "## Stretch Goals\n",
    "- [ ] Make multiple PDPs with 1 feature in isolation.\n",
    "- [ ] Make multiple PDPs with 2 features in interaction. \n",
    "- [ ] Use Plotly to make a 3D PDP.\n",
    "- [ ] Make PDPs with categorical feature(s). Use Ordinal Encoder, outside of a pipeline, to encode your data first. If there is a natural ordering, then take the time to encode it that way, instead of random integers. Then use the encoded data with pdpbox.I Get readable category names on your plot, instead of integer category codes.\n",
    "\n",
    "## Links\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "- [Plotly: 3D PDP example](https://plot.ly/scikit-learn/plot-partial-dependence/#partial-dependence-of-house-value-on-median-age-and-average-occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "import random as ran\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import f_classif, chi2, SelectKBest, SelectPercentile, SelectFpr, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vgcSun_hot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTe=pd.concat([df[:903],df[3615:4518]])\n",
    "dfTr=pd.concat([df[904:3614],df[4519:9034]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"winner\"\n",
    "features = df.columns.drop(\"winner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = features[788:]\n",
    "categorical_features = features[1:788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a group of columns based on a list.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection Pipelines\n",
    "numPipe = Pipeline( [\n",
    "    (\"ncol\", ColumnSelector(numeric_features)),\n",
    "    (\"nkbe\", SelectKBest(score_func=f_classif, k=111))\n",
    "    ] )\n",
    "\n",
    "catPipe = Pipeline( [\n",
    "    (\"ccol\", ColumnSelector(categorical_features)),\n",
    "    (\"ckbe\", SelectKBest(score_func=chi2, k=726))\n",
    "    ] )\n",
    "\n",
    "feats = FeatureUnion([('nums', numPipe), ('cats', catPipe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = Pipeline([\n",
    "      (\"feats\", feats),\n",
    "      (\"XGBoost\",\n",
    "        XGBClassifier(\n",
    "            n_estimators = 300,\n",
    "            max_depth=7,\n",
    "            learning_rate=.5,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "  ])\n",
    "\n",
    "Ran = Pipeline([\n",
    "      (\"feats\", feats),\n",
    "      (\"Rand\", RandomForestClassifier(n_estimators=100, n_jobs=-1, max_features = 0.91))\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('feats',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('nums',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('ncol',\n",
       "                                                                  ColumnSelector(cols=Index(['team1_Nones', 'team1_Normals', 'team1_Fightings', 'team1_Flyings',\n",
       "       'team1_Poisons', 'team1_Grounds', 'team1_Rocks', 'team1_Bugs',\n",
       "       'team1_Ghosts', 'team1_Steels',\n",
       "       ...\n",
       "       'team2_Normal_immunity', 'team2_Fighting_imm...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ran.fit(dfTe[features], dfTe[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5472664359861592"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ran.score(dfTr[features], dfTr[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 18.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    # 'feat__nums__nimp__strategy' : ['mean', 'median'],\n",
    "    # 'feats__nums__nkbe__k' : randint(1, len(numeric_features)),\n",
    "    #'feat__nums__nkbe__score_func',\n",
    "    'feats__cats__ckbe__k' : randint(1, len(categorical_features)),\n",
    "    #'feat__cats__ckbe__score_func',\n",
    "    # 'RF__max_depth': [5, 10, 15, 20, None],\n",
    "    'Rand__max_features':uniform(0, 1),\n",
    "    #'RF__max_leaf_nodes',\n",
    "    #'RF__min_samples_leaf',\n",
    "    #'RF__min_samples_split',\n",
    "    # 'RF__n_estimators':randint(50, 500)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    Ran, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=100, \n",
    "    cv=3, \n",
    "    scoring='accuracy', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(df[features], df[target]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'Rand__max_features': 0.9133514547334742, 'feats__cats__ckbe__k': 726, 'feats__nums__nkbe__k': 111}\n",
      "Cross-validation Accuracy 0.5904361301748948\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters', search.best_params_)\n",
    "print('Cross-validation Accuracy', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 folds: 0.5853378365134899\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, df[features], df[target], cv=5, scoring='accuracy')\n",
    "print(f'Accuracy for 5 folds:', scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "model.fit(dfTr[features], dfTr[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(dfTe[features], dfTe[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 5 folds: [0.59015487 0.59679204 0.56423034 0.56976744 0.58250277]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5806894912729447"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, df[features], df[target], cv=5, scoring='accuracy')\n",
    "print(f'Accuracy for 5 folds:', scores)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_applied_modeling_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
